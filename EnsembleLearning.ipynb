{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f35976d-bdf2-407e-bef0-f2b1b68ab053",
   "metadata": {},
   "source": [
    "Q21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759631b9-dd6d-4b74-8c50-309f27d22be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "bag_clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=50, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "print(f'Bagging Classifier Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bbfd3b-7182-4423-be5f-1c275699328e",
   "metadata": {},
   "source": [
    "Q22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68745b9-5abf-4d09-9c76-a37d653e9fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "bag_reg = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=50, random_state=42)\n",
    "bag_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = bag_reg.predict(X_test)\n",
    "\n",
    "print(f'Bagging Regressor MSE: {mean_squared_error(y_test, y_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e57b54-12aa-4218-a2f9-867fa5eb1c4b",
   "metadata": {},
   "source": [
    "Q23.Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce6b94-7daf-43e4-9457-f0e5f4453467",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "\n",
    "data = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = pd.Series(rfc.feature_importances_, index=data.feature_names).sort_values(ascending=False)\n",
    "print('Feature Importances:')\n",
    "print(feature_importances.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63bafd0-9e7f-40cb-b2fb-e1599ea12d1a",
   "metadata": {},
   "source": [
    "Q24. Train a Random Forest Regressor and compare its performance with a single Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f775ab-7533-432c-ba04-115c871eebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "dt_reg = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "rf_reg.fit(X_train, y_train)\n",
    "dt_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_reg.predict(X_test)\n",
    "y_pred_dt = dt_reg.predict(X_test)\n",
    "\n",
    "print(f'Random Forest Regressor MSE: {mean_squared_error(y_test, y_pred_rf):.4f}')\n",
    "print(f'Decision Tree Regressor MSE: {mean_squared_error(y_test, y_pred_dt):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1b6f0c-582b-4b06-aa18-54ac3f5c2e29",
   "metadata": {},
   "source": [
    "Q25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8552def3-4aef-4634-bc69-ccc9ec7c9892",
   "metadata": {},
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_oob = RandomForestClassifier(n_estimators=50, oob_score=True, random_state=42, bootstrap=True)\n",
    "rf_oob.fit(X_train, y_train)\n",
    "\n",
    "print(f'Random Forest OOB Score: {rf_oob.oob_score_:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b63f01-4760-43f7-86c4-cca18d708c5d",
   "metadata": {},
   "source": [
    "Q26. 2 Train a Bagging Classifier using SVM as a base estimator and print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab3450-7a3c-4094-b83b-9e89f8bafb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "bag_svm = BaggingClassifier(base_estimator=SVC(), n_estimators=50, random_state=42)\n",
    "bag_svm.fit(X_train, y_train)\n",
    "y_pred_svm = bag_svm.predict(X_test)\n",
    "\n",
    "print(f'Bagging Classifier with SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7902a58d-2ca0-44fa-915e-b697f8422a7a",
   "metadata": {},
   "source": [
    "Q27. 2 Train a Random Forest Classifier with different numbers of trees and compare accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ed5bf-194f-4777-9ab2-90e1a6e8fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "bag_svm = BaggingClassifier(base_estimator=SVC(), n_estimators=50, random_state=42)\n",
    "bag_svm.fit(X_train, y_train)\n",
    "y_pred_svm = bag_svm.predict(X_test)\n",
    "\n",
    "print(f'Bagging Classifier with SVM Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8c3ef9-ad25-4b19-bdad-135e31c7cc0d",
   "metadata": {},
   "source": [
    "Q28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc192f7-2700-45bb-bf0a-a73b408e6f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "bag_lr = BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=50, random_state=42)\n",
    "bag_lr.fit(X_train, y_train)\n",
    "y_pred_proba = bag_lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(f'Bagging Classifier with Logistic Regression AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c415bfc-3038-4e29-90d0-691131d00b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q29. Train a Random Forest Regressor and analyze feature importance scores\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pandas as pd\n",
    "\n",
    "rf_reg = RandomForestRegressor(n_estimators=50, random_state=42)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "feature_importances = pd.Series(rf_reg.feature_importances_).sort_values(ascending=False)\n",
    "print('Random Forest Regressor Feature Importances:')\n",
    "print(feature_importances.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb1523e-68f3-412e-bf3c-7662bd2bf308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q30. Train an ensemble model using both Bagging and Random Forest and compare accuracy\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('bagging', bag_svm), ('random_forest', rf_oob)], voting='hard')\n",
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "\n",
    "print(f'Ensemble Model Accuracy: {accuracy_score(y_test, y_pred_voting):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba78802f-b950-468c-9f5b-5dca81faba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier and tune hyperparameters using GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {'n_estimators': [10, 50, 100], 'max_depth': [5, 10, None]}\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f'Best Parameters: {grid_search.best_params_}')\n",
    "print(f'Best Score: {grid_search.best_score_:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e3b2cf-aa9d-461f-a356-9ce34ba2fa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Bagging Regressor with different numbers of base estimators and compare performance\n",
    "n_estimators_list = [10, 50, 100]\n",
    "for n in n_estimators_list:\n",
    "    bag_reg = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=n, random_state=42)\n",
    "    bag_reg.fit(X_train_reg, y_train_reg)\n",
    "    y_pred_reg = bag_reg.predict(X_test_reg)\n",
    "    print(f'Bagging Regressor with {n} base estimators MSE: {mean_squared_error(y_test_reg, y_pred_reg):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba47fdf-84bd-458e-bb7c-0af316a153e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier and analyze misclassified samples\n",
    "y_pred = rfc.predict(X_test)\n",
    "misclassified = X_test[y_pred != y_test]\n",
    "print(f'Number of Misclassified Samples: {len(misclassified)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a89dc0e-89c4-4ac8-ac58-1f3bf77cd9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test)\n",
    "\n",
    "print(f'Decision Tree Classifier Accuracy: {accuracy_score(y_test, y_pred_dt):.4f}')\n",
    "print(f'Bagging Classifier Accuracy: {accuracy_score(y_test, y_pred_svm):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c318a-4ad4-4398-81ef-f2069b94639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier and visualize the confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = rfc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c3d668-8731-443f-9827-b21559339dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [('dt', DecisionTreeClassifier()), ('svm', SVC(probability=True)), ('lr', LogisticRegression())]\n",
    "stack_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "stack_clf.fit(X_train, y_train)\n",
    "y_pred_stack = stack_clf.predict(X_test)\n",
    "\n",
    "print(f'Stacking Classifier Accuracy: {accuracy_score(y_test, y_pred_stack):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd752fa5-9536-456e-9d7c-75b1b178d6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier and print the top 5 most important features\n",
    "feature_importances = pd.Series(rfc.feature_importances_, index=data.feature_names).sort_values(ascending=False)\n",
    "print('Top 5 Important Features:')\n",
    "print(feature_importances.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9109df6b-be22-4c06-b344-c1ef8c6e440f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred_bag = bag_clf.predict(X_test)\n",
    "print(f'Precision: {precision_score(y_test, y_pred_bag):.4f}')\n",
    "print(f'Recall: {recall_score(y_test, y_pred_bag):.4f}')\n",
    "print(f'F1 Score: {f1_score(y_test, y_pred_bag):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a269060d-8280-4edc-b8ed-ed21ae003fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier and analyze the effect of max_depth on accuracy\n",
    "max_depth_list = [5, 10, None]\n",
    "for depth in max_depth_list:\n",
    "    rfc = RandomForestClassifier(n_estimators=50, max_depth=depth, random_state=42)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    print(f'Random Forest Classifier with max_depth={depth} Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05e9185-a558-45ae-84c3-5cfccf0a82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "for base_estimator in [DecisionTreeRegressor(), KNeighborsRegressor()]:\n",
    "    bag_reg = BaggingRegressor(base_estimator=base_estimator, n_estimators=50, random_state=42)\n",
    "    bag_reg.fit(X_train_reg, y_train_reg)\n",
    "    y_pred_reg = bag_reg.predict(X_test_reg)\n",
    "    print(f'Bagging Regressor with {type(base_estimator).__name__} MSE: {mean_squared_error(y_test_reg, y_pred_reg):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e6491-1c0f-424c-a2da-3b2f599f1501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred_proba = rfc.predict_proba(X_test)[:, 1]\n",
    "print(f'Random Forest Classifier ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482301b2-4436-4dad-bbd1-a871b9c35afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred_proba = rfc.predict_proba(X_test)[:, 1]\n",
    "print(f'Random Forest Classifier ROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303b1482-a635-4d3d-99d2-dec2dcf2aa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Bagging Classifier and evaluate its performance using cross-validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "bag_scores = cross_val_score(bag_clf, X, y, cv=5, scoring='accuracy')\n",
    "print(f'Bagging Classifier Cross-Validation Accuracy: {bag_scores.mean():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f884e61-aaaa-40d1-998d-c7e44a91030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest Classifier and plot the Precision-Recall curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4524c403-d2ef-46c9-977f-eeee025ff9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy\n",
    "estimators = [('rf', RandomForestClassifier(n_estimators=50)), ('lr', LogisticRegression())]\n",
    "stack_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "\n",
    "stack_clf.fit(X_train, y_train)\n",
    "y_pred_stack = stack_clf.predict(X_test)\n",
    "\n",
    "print(f'Stacking Classifier Accuracy: {accuracy_score(y_test, y_pred_stack):.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db090abc-7b39-4c20-9eb0-9ba2b09ea726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Bagging Regressor with different levels of bootstrap samples and compare performance\n",
    "bootstrap_samples = [0.5, 1.0]\n",
    "for sample in bootstrap_samples:\n",
    "    bag_reg = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators=50, max_samples=sample, random_state=42)\n",
    "    bag_reg.fit(X_train_reg, y_train_reg)\n",
    "    y_pred_reg = bag_reg.predict(X_test_reg)\n",
    "    print(f'Bagging Regressor with max_samples={sample} MSE: {mean_squared_error(y_test_reg, y_pred_reg):.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
